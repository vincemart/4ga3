Libraries

```{r message=FALSE, warning=FALSE}
library(cartogram) # Create Cartograms with R
library(gstat) # Spatial and Spatio-Temporal Geostatistical Modelling, Prediction and Simulation
library(glue) # Interpreted String Literals
library(here) # A Simpler Way to Find Your Files
library(leaflet) # Create Interactive Web Maps with the JavaScript 'Leaflet' Library
library(plotly) # Create Interactive Web Graphics via 'plotly.js'
library(sf) # Simple Features for R
library(spatstat) # Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests
library(spdep) # Spatial Dependence: Weighting Schemes, Statistics
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(units) # Measurement Units for R Vectors
```

```{r}
#Import data ASK ABOUT PATHS
AirData = st_read(glue::glue(here::here(), "/data-raw/AirData/AirData.shx")) 
summary(AirData)

City = st_read(glue::glue(here::here(), "/data-raw/Hamilton/City_neighbourhoods.shx"))
City <- st_transform(City, 26917)
st_crs(City)
```

Plot. Stations are point data, but what we are interested is the concentrations (they are fields)

```{r}
ggplot() +
  geom_sf(data = City, fill = "gray", color = "black", alpha = 0.5, size = 0.3) +
  geom_sf(data = AirData, aes(shape = POLLUTANT_)) +
  coord_sf()
```

I don't know how to deal with temporal data like this, so i chose NO2 pollutants with the end date of 2022-02-21 as an example.
Going through area data readings:

```{r}
AdataEX = filter(filter(AirData, END_DATE == "2022-02-21"), POLLUTANT_ == "NO2")
test = filter(filter(AirData, END_DATE == "2022-02-21"), POLLUTANT_ == "SO2")
#FIND A WAY TO AVERAGE STATIONS (average different times together)
```

Suggestion by AP:

Use group_by() to group observations, and summarize() to obtain averages.

To do that, we need unique IDs for the stations, which currently don't exist in the data frame. So we want to see how many unique stations are there:
```{r}
AirData |>
  distinct(geometry)
```

According to this there are 68 station, which sounds like a lot. Some plots show what seems fewer stations. See if there is any overlap between buffers:
```{r}
station_buffers <- AirData |>
  distinct(geometry) |>
  st_buffer(dist = 100)

station_buffers |> 
  mutate(area = st_area(geometry)) |>
  ggplot() + 
  geom_sf(aes(size = drop_units(area) * 100))
```

It looks like all the locations are unique.

Let us give a unique ID to the location of the station:
```{r}
station_id <- AirData |>
  distinct(geometry) |>
  mutate(station_id = 1:n(),
         station_id = factor(station_id))
```

After creating unique station ids, join to the AirData:
```{r}
AirData <- AirData |>
  st_join(station_id)
```

Examination of the table shows that measurement of pollutants is not continuous which means that averages over time are not appropriate. Select a single two-week period for the project. Probably, the one with most observations by pollutant:
```{r}
AirData |>
  st_drop_geometry() |>
  group_by(END_DATE, POLLUTANT_) |>
  summarize(n_stations = n(),
            .groups = "drop") |>
  arrange(desc(n_stations))
```



Leaflet

```{r}
leaflet(data = AdataEX) |>
  setView(lng = -79.86, lat = 43.25, zoom = 10) |>
  addTiles() |>
  addMarkers(data = AdataEX, ~LONGITUDE, ~LATITUDE)
```

Spatially continuous data

```{r}
ggplot() +
  geom_sf(data = City, fill = "gray", color = "black", alpha = 0.5, size = 0.3) +
  geom_sf(data = AdataEX, aes(color = CONCENTRAT, size = CONCENTRAT), alpha = 0.8) +
  scale_color_distiller(palette = "YlOrRd", direction = 1) +
  coord_sf()
```

```{r}
plot_ly(data = AdataEX, x = ~LONGITUDE, y = ~LATITUDE, z = ~CONCENTRAT, marker = list(color = ~CONCENTRAT, colorscale = c("Yellow", "Red"), showscale = TRUE)) |>
  add_markers()
```

Interpolation methods: From lab

```{r}
#Create Voronoi polygons
voronoiP = do.call(c, st_geometry(AdataEX)) |>
  st_voronoi() |>
  st_collection_extract()
voronoiP <- st_set_crs(voronoiP, 26917)

#Replace point with polygon data
poly_data <- AdataEX
poly_data$geometry = voronoiP[unlist(st_intersects(AdataEX, voronoiP))] 

#Bounding box does not work
bbox = st_sf(st_sfc(
  st_polygon(list(rbind(c(-80.3, 43.0), 
                        c(-79.5, 43.0), 
                        c(-79.5, 43.5), 
                        c(-80.3, 43.5), 
                        c(-80.3, 43.0))))
)) #Thank you to the TA for this solution
st_crs(bbox) <- 4326
bbox <- st_transform(bbox, 26917)
poly_data <- poly_data |>
  st_intersection(bbox)

#Plot Voronoi polygons (cannot find a way to )
ggplot(poly_data) +
  geom_sf(aes(fill = CONCENTRAT)) +
  geom_sf(data = AdataEX, size = 0.2) +
  scale_fill_distiller(palette = "YlOrRd", direction = 1) +
  geom_sf(data = City, fill = "gray", color = "black", alpha = 0.1, size = 0.3)

```

IDW

```{r}
#Create owin object
BoxOwin = as.owin(bbox)

#Create ppp object
AdataEX <- relocate(AdataEX, CONCENTRAT, .after = LATITUDE)
Datappp = as.ppp(X = AdataEX[6:8], W = BoxOwin)

#Create IDW surface BROKEN
#idw_map = idw(Datappp, power = 1.5)
#plot(idw_map) #Ignore the long and lat maps, I have no idea why its doing that
```

k-point means (I dont even know, no isdas package also so just skip)

```{r}
##Create prediction grid
#Xseq = seq(-80.3, -79.5, 0.005)
#Yseq = seq(43.0, 43.5, 0.005)
#Target = expand.grid(x = Xseq, y = Yseq) |>
#  st_as_sf(coords = c("x", "y"))

##Create k point means
#k_data = kpointmean(source_xy = AdataEX, target_xy = Target, z = CONCENTRAT, k = 2) |>
#  rename(CONCENTRAT = z)

##Plot
#ggplot() +
#  geom_sf(data = k_data, aes(color = CONCENTRAT)) +
#  scale_color_distiller(palette = "YlOrRd", direction = 1)
```

Trend Surface Estimations
```{r}
AdataEX <- mutate(AdataEX, X3 = LONGITUDE^3, X2Y = LONGITUDE^2 * LATITUDE, X2 = LATITUDE^2, XY = LONGITUDE * LATITUDE, Y2 = LATITUDE^2, XY2 = LONGITUDE * LATITUDE^2, Y3 = LATITUDE^3, X = LONGITUDE, Y = LATITUDE)

#Linear polynomial
Trend1 = lm(formula = CONCENTRAT ~ X + Y, data = AdataEX)
summary(Trend1)

#Quadratic polynomial
Trend2 = lm(formula = CONCENTRAT ~ X2 + X + XY + Y + Y2, data = AdataEX)
summary(Trend2)

#Cubic polynomial
Trend3 = lm(formula = CONCENTRAT ~ X3 + X2Y + X2 + X + XY + Y + Y2 + XY2 + Y3, data = AdataEX)
summary(Trend3)

```

Choosing [trend] because ...:

```{r}
#Interpolation grid
xSeq = seq(-80.3, -79.5, 0.005)
ySeq = seq(43.0, 43.5, 0.005)
Intergrid = expand.grid(X = Xseq, Y = Yseq)
Intergrid <- mutate(Intergrid, X3 = X^3, X2Y = X^2 * Y, X2 = X^2, XY = X * Y, Y2 = Y^2, XY2 = X * Y^2, Y3 = Y^3)
Prediction <- predict(Trend1, newdata = Intergrid, se.fit = TRUE, interval = "prediction", level = 0.95)
summary(Prediction$fit)
```
```{r}
#lm Surface Interpolation
Zp = matrix(data = Prediction$fit[,1], nrow = 101, ncol = 161, byrow = TRUE)
Zp_low = matrix(data = Prediction$fit[,2], nrow = 101, ncol = 161, byrow = TRUE)
Zp_high = matrix(data = Prediction$fit[,3], nrow = 101, ncol = 161, byrow = TRUE)

#Plot 3D
plot_ly(x = ~Xseq, y = ~Yseq, z = ~Zp, type = "surface", colors = "YlOrRd") |>
  add_surface(x = ~Xseq, y = ~Yseq, z = ~Zp_low, opacity = 0.5, showscale = FALSE) |>
  add_surface(x = ~Xseq, y = ~Yseq, z = ~Zp_high, opacity = 0.5, showscale = FALSE) |>
  layout(scene = list(aspectmode = "manual", aspectratio = list(x = 1, y = 1, z = 1)))

#Create add residuals to dataframe
AdataEX$PredRes <- ifelse(Trend1$residuals > 0, "Positive", "Negative")

#Plot residuals
ggplot(data = AdataEX, aes(x = X, y = Y, color = PredRes)) +
  geom_point() +
  coord_equal()

#Morans I of residuals
WeightList <- as.matrix(AdataEX[,6:7])
WeightList <- subset(WeightList, select = -geometry)
WeightList <- transform(WeightList, LONGITUDE = as.numeric(LONGITUDE), LATITUDE = as.numeric(LATITUDE))
WeightList <-
  knearneigh(WeightList, k = 3) |> 
  knn2nb() |> 
  nb2listw() 
moran.test(x = Trend1$residuals, listw = WeightList)
```

Linear looks the best, the others REALLY dont look good
  
Semivariogram 

```{r}
#Get semivariogram of data set
Vari = variogram(CONCENTRAT ~ 1, data = AdataEX)
#Plot
ggplot(data = Vari, aes(x = dist, y = gamma)) + 
  geom_point() + 
  geom_text(aes(label = np), nudge_y = -2) + 
  xlab("Distance") +
  ylab("Semivariance")
```

```{r}
#Semivariogram of the residuals 
AdataEX$TrendRes <- Trend1$residuals
VariRes = variogram(TrendRes ~ 1, data = AdataEX)

#Get best fitting model
VariRes_Th = fit.variogram(VariRes, model = vgm("Exp", "Sph", "Gau"))
VariRes_Th

Fit_line <- variogramLine(VariRes_Th, maxdist = 12500)
ggplot(data = VariRes, aes(x = dist, y = gamma)) + 
  geom_point() + 
  geom_text(aes(label = np), nudge_y = -2) + 
  geom_line(data = Fit_line, aes(x = dist, y = gamma)) +
  xlab("Distance") +
  ylab("Semivariance")
```

Kriging
```{r}
#Kriging 
IntergridSF = Intergrid |> st_as_sf(coords = c("X", "Y"), remove = FALSE, crs = 26917)
IntergridSF <- mutate(IntergridSF, X3 = X^3, X2Y = X^2 * Y, X2 = X^2, XY = X * Y, Y2 = Y^2, XY2 = X * Y^2, Y3 = Y^3) #in case of model change
KrigModel = krige(CONCENTRAT ~ X + Y, filter(AdataEX, OBJECTID != 6), IntergridSF, VariRes_Th) #Bandaid fix, filter out duplicate using object id. Using higher order polynomials still does not work well

#Extract results
Kpred = matrix(data = KrigModel$var1.pred, nrow = 101, ncol = 161, byrow = TRUE) #ISSUE: does not work when there are points in the data with same coordinates

#Plot interpolation
plot_ly(x = ~Xseq, y = ~Yseq, z = ~Kpred, type = "surface", colors = "YlOrRd") |> 
  layout(scene = list(aspectmode = "manual", aspectratio = list(x = 1, y = 1, z = 1)))

```

How to turn into an area data: take points and intersect/join with polygons, group by zone, get average.

###HEALTH DATA START

```{r}
#Import
COPDdata = st_read(glue::glue(here::here(), "/data-raw//COPD/Hamilton_COPDdata.shx"))
summary(COPDdata)

COPDdata$TOT35_Rate = COPDdata$COPD_T35 / COPDdata$TPOP_35
```

```{r}
#Chloropleth
ggplot(COPDdata) +
  geom_sf(aes(fill = cut_number(TOT35_Rate, 5)), color = "black", size = 0.1) +
  scale_fill_brewer(palette = "YlOrRd") +
  coord_sf() +
  labs(fill = "Rate of COPD for Total Population Over 35")

#Cartogram version
RateCarto = cartogram_cont(COPDdata, weight = "TOT35_Rate")
ggplot(RateCarto) +
  geom_sf(aes(fill = cut_number(TOT35_Rate, 5)), color = "black", size = 0.1) +
  scale_fill_brewer(palette = "YlOrRd") +
  coord_sf() +
  labs(fill = "Rate of COPD for Total Population Over 35")
```

```{r}
#Spatial Moving Average
COPDweight = nb2listw(poly2nb(pl = COPDdata))
RateSMA = lag.listw(x = COPDweight, COPDdata$TOT35_Rate)
COPDdata <- left_join(COPDdata, data.frame(HNHB_ID = COPDdata$HNHB_ID, RateSMA), by = "HNHB_ID")

#Plot
ggplot() +
  geom_sf(data = COPDdata, aes(fill = cut_number(RateSMA, 5)), color = "black") +
  scale_fill_brewer(palette = "YlOrRd") +
  labs(fill = "SMA of Rate of COPD for Total Population Over 35") +
  coord_sf()
```

```{r}
#Moran plot and test
moran.test(COPDdata$TOT35_Rate, COPDweight)
#moran.plot(COPDdata$TOT35_Rate, COPDweight, xlab = "Rate", ylab = "Lagged Rate") #STRANGE ERROR
```

```{r}
#Local Moran
RateLM = localmoran(COPDdata$TOT35_Rate, COPDweight)
summary(RateLM)

#Function
localmoran.map <- function(p, listw, VAR, by){
  # p is a simple features object
  require(tidyverse) # Easily Install and Load the 'Tidyverse'
  require(spdep) # Spatial Dependence: Weighting Schemes, Statistics
  require(plotly) # Create Interactive Web Graphics via 'plotly.js'
  
  df_msc <- p |> 
    rename(VAR = as.name(VAR),
              key = as.name(by)) |>
    transmute(key,
              VAR,
              Z = (VAR - mean(VAR)) / var(VAR),
              SMA = lag.listw(listw, Z),
              Type = case_when(Z < 0 & SMA < 0 ~ "LL",
                               Z > 0 & SMA > 0 ~ "HH",
                               TRUE ~ "HL/LH"))
  
  local_I <- localmoran(df_msc$VAR, listw)
  
  colnames(local_I) <- c("Ii", "E.Ii", "Var.Ii", "Z.Ii", "p.val")
  
  df_msc <- left_join(df_msc, 
                      data.frame(key = df_msc$key, 
                                 local_I),
                      by = "key")
  
  plot_ly(df_msc) |>
    add_sf(type = "scatter",
           split = ~(p.val < 0.05), 
           color = ~Type, 
           colors = c("red", 
                      "khaki1",
                      "dodgerblue", 
                      "dodgerblue4")) 
}

localmoran.map(COPDdata, COPDweight, "TOT35_Rate", by = "HNHB_ID")
```

```{r}
#G*
gistar.map <- function(p = p, listw = listw, VAR = VAR, by = by){
require(tidyverse) # Easily Install and Load the 'Tidyverse'
require(spdep) # Spatial Dependence: Weighting Schemes, Statistics
require(sf) # Simple Features for R
require(plotly) # Create Interactive Web Graphics via 'plotly.js'
p <- mutate(p, key = p[[by]])
df.lg <- localG(p[[VAR]], listw)
df.lg <- as.numeric(df.lg)
df.lg <- data.frame(Gstar = df.lg, p.val = 2 * pnorm(abs(df.lg), lower.tail = FALSE))
df.lg <- mutate(df.lg,
Type = case_when(Gstar < 0 & p.val <= 0.05 ~ "Low Concentration",
Gstar > 0 & p.val <= 0.05 ~ "High Concentration",
TRUE ~ "Not Signicant"))
p <- left_join(p,
data.frame(key = p[[by]], df.lg))
plot_ly(p) |>
add_sf(split = ~(p.val < 0.05), color = ~Type, colors = c("red", "dodgerblue", "gray"))
}
#Binary weights
COPDbinW <- COPDdata |>
st_centroid() |>
dnearneigh(d1 = 0, d2 = 3) #Use disance of 3km
COPDbinW <- nb2listw(include.self(COPDbinW), style = "B")

#Plots
#localG(COPDdata$TOT35_Rate, COPDbinW) #prob not useful to show stats
gistar.map(p = COPDdata, listw = COPDbinW, VAR = "TOT35_Rate", by = "HNHB_ID")
```

DO CHAPTER 27 (regression models for multiple variables) AND 29 (remedial actions) ONCE YOU CAN COMBINE OTHER DATASET TO THIS ONE


